{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import urllib\n",
    "from urllib.parse import quote\n",
    "\n",
    "with open('./top-level-lcc.json', 'r') as reader:\n",
    "    basic = json.load(reader)\n",
    "\n",
    "with open('./v2_merged_lcc.json', 'r') as reader: #using the version with a lot of detail for black history and lgbtq history\n",
    "    detail = json.load(reader)\n",
    "\n",
    "syllabus = pd.read_csv('./edstud_lgbt_med.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lcc(call_number):\n",
    "    if call_number == None:\n",
    "        return None\n",
    "    #specifically for how OL formats their LCC call numbers\n",
    "    out = call_number.replace('-', '') #remove hyphen\n",
    "    out = re.sub(r'(?<=[A-Z])0+', '', out) #Remove leading zeros after the letters segment\n",
    "    \n",
    "    # Adjust regex match for letter and number segments, ensuring float conversion for fractional part\n",
    "    match = re.match(r'([A-Z]+)(\\d+(\\.\\d+)?)', out)\n",
    "    \n",
    "    if match:\n",
    "        return (match.group(1), float(match.group(2)))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lookup_meaning(code): #takes in tuple (call number)\n",
    "    l = []\n",
    "\n",
    "    try:\n",
    "        d = detail[code[0]]\n",
    "        for i in d:\n",
    "            if code[1] >= i['start'] and code[1] <= i['stop']:\n",
    "                l.append(i['subject'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return l\n",
    "    #returns a list of definitions for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Special classes', 'People with disabilities', 'Protection, assistance and relief', 'Social pathology.  Social and public welfare.']\n",
      "['General', 'History of Central Europe']\n",
      "['Afro-Americans', 'Status and development since emancipation', 'United States', 'Elements in the population', 'United States. Elements in the population. African Americans. Social conditions. Social life and customs.']\n",
      "['Languages of Eastern Asia, Africa, Oceania', 'Individual authors and works', 'Japanese language and literature', 'Japanese literature']\n",
      "['History', 'History of Asia']\n"
     ]
    }
   ],
   "source": [
    "ex1 = 'HV-1568.00000000.B376 2016' #The Minority Body by Elizabeth Barnes\n",
    "ex2 = 'DAW1008.00000000.B37 1987' #A guide to Central Europe by Richard Bassett\n",
    "ex3 = 'E--185.86.00000000.H739 2001' #Salvation: Black People and Love by bell hooks\n",
    "ex4 = 'PL-0788.40000000.G4 E5 2000' #Genji Monogatari by Murasaki Shikibu\n",
    "ex5 = 'DS-0032.80000000' #Orientalism by Edward Said\n",
    "\n",
    "print(lookup_meaning(split_lcc(ex1)))\n",
    "print(lookup_meaning(split_lcc(ex2)))\n",
    "print(lookup_meaning(split_lcc(ex3)))\n",
    "print(lookup_meaning(split_lcc(ex4)))\n",
    "print(lookup_meaning(split_lcc(ex5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search by LCCN or ISBN on OpenLibrary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchby_lccn(lccn, fields = 'author_name,subject,lcc,title', limit = 5): \n",
    "    r = []\n",
    "    response = requests.get(f'https://openlibrary.org/search.json?q=lcc:{lccn}&fields={fields}&limit={limit}').json()\n",
    "    return response['docs']\n",
    "\n",
    "def searchby_isbn(isbn, field = 'lcc', limit = 1):\n",
    "    time.sleep(2) #being polite\n",
    "    response = requests.get(f'https://openlibrary.org/search.json?q=isbn:{isbn}&fields={field}&limit={limit}').json()\n",
    "\n",
    "    if bool(response['docs']): #falsy\n",
    "        #print(response['docs'], isbn) #error checking\n",
    "\n",
    "        if bool(response['docs'][0].get(f'{field}')): #if there is an lcc\n",
    "            return response['docs'][0].get(f'{field}')[0] #string, first lcc returned\n",
    "    else:\n",
    "        return '' #nothing returned\n",
    "\n",
    "def reformat_openlibrary_lccn(syllabus): #doesn't account for specific subclasses\n",
    "    lccn_tup = []\n",
    "\n",
    "    for isbn in syllabus['isbn']: #get the lccn\n",
    "        val = split_lcc(searchby_isbn(isbn)) #after querying Open library, split them into tuples\n",
    "\n",
    "        if val is not None:\n",
    "            lccn_tup.append(val)\n",
    "            \n",
    "    return lccn_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search by call number: [{'lcc': ['HV-3181.00000000.S64', 'HV-3181.00000000'], 'title': 'Black Empowerment'}]\n",
      "Search by class: [{'title': 'The Roman Breviary'}]\n",
      "Search by Subclass: [{'title': 'The Roman Breviary'}]\n",
      "Search range: [{'title': 'The Canterbury Tales'}]\n",
      "Search with Example 2: [{'subject': ['Guidebooks', 'Travel & holiday guides', 'Travel Guides', 'Travel', 'Travel - Foreign', 'Central Europe', 'Europe - General']}]\n"
     ]
    }
   ],
   "source": [
    "#queries\n",
    "#1. Direct call number: HV3181*\n",
    "print('Search by call number:', searchby_lccn('HV3181\\*', 'title, lcc', 1))\n",
    "\n",
    "#2. Anything under a broad category: H* includes H, HA, HB, etc.\n",
    "print('Search by class:', searchby_lccn('H\\*', 'title', 1))\n",
    "\n",
    "#3. Anything under a specific category: H-- includes only H, HA- includes only HA\n",
    "print('Search by Subclass:', searchby_lccn('H--\\*', 'title', 1))\n",
    "#books might differ slightly in exact code, so i limit to only title here, you can look at the lcc return list for more details\n",
    "\n",
    "#4. A range of outputs: HQ TO HV\n",
    "print('Search range:', searchby_lccn('[HQ TO HV]', 'title', 1)) #can also do this with numbers\n",
    "\n",
    "#5. A string of call numbers is not allowed to my understanding\n",
    "#search_lccn('[HJ6799, HJ8001]', 'title,lcc', 2)\n",
    "\n",
    "#this could be made simpler; right now i return a tuple for simplification when looking up keys in the dictionary\n",
    "print(\"Search with Example 2:\", search_lccn(split_lcc(ex2)[0] + str(split_lcc(ex2)[1]), 'subject', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "lccn_tup = reformat_openlibrary_lccn(syllabus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for k, v in prefixes:\n",
    "    d = detail[k]\n",
    "    for i in d:\n",
    "        if code[1] >= i['start'] and code[1] <= i['stop']:\n",
    "            l.append(i['subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find common parents in order to make the most efficient search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_parents(lccn, lcc_data):\n",
    "    init = lccn[0] + str(lccn[1])\n",
    "    all_parents = {init} #let itself be a \"parent\" just in case!\n",
    "\n",
    "    try:\n",
    "        d = lcc_data[lccn[0]] #key is first element in list\n",
    "\n",
    "        for i in d: #for each dictionary in the list\n",
    "            if lccn[1] >= i['start'] and lccn[1] <= i['stop']: #check if a subset\n",
    "\n",
    "                #if this is the deepest node; if itself is the only parent, until now, then overwrite\n",
    "                if len(i['parents']) >= len(all_parents): \n",
    "                    all_parents = i['parents']\n",
    "        return all_parents\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_most_recent_common_parent(tupes, lcc_data):\n",
    "    node_parent_sets = [get_all_parents(t, lcc_data) for t in tupes]\n",
    "    \n",
    "    prefixes = {}\n",
    "    inter = {}\n",
    "    #get all parents for each prefix\n",
    "    for t in tupes:\n",
    "        val = get_all_parents(t, lcc_data)\n",
    "        if val != None:\n",
    "            if t[0] not in prefixes.keys():\n",
    "                prefixes[t[0]] = [val] #make a list with all the floats\n",
    "            else:\n",
    "                prefixes[t[0]].append(val) #make a list with all the floats\n",
    "\n",
    "    for k,v in prefixes.items():\n",
    "        inter[k] = list(set(v[0]).intersection(*map(set, v[1:])))[0] #make it a string\n",
    "\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HQ': 'HQ1-2044', 'LB': 'LB5-3640', 'LC': 'LC8-6691', 'BF': 'BF1-990', 'PZ': 'PZ1-90'}\n"
     ]
    }
   ],
   "source": [
    "mrcp = find_most_recent_common_parent(lccn_tup, detail)\n",
    "print(mrcp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our area of desired diversity (perspective of interest in other words) is LGBTQ Studies. Our overarching discipline area is Education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could this level of granularity be useful? Unsure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./updated_lgbtq_lcc.json', 'r') as reader: #everything about lgbtq studies, specifically\n",
    "    diversity = json.load(reader) #in practice, we call also ONLY load in the relevant subclasses\n",
    "\n",
    "diversity_subset = {k: v for k,v in diversity.items() if k in mrcp.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Human sexuality. Sex. Sexual orientation.', 'Kinsey, Alfred.', 'Bisexuality. General works.', 'Bisexuality. By region or country, A-Z.', 'Homosexuality. Lesbianism. Periodicals. Serials.', 'Homosexuality. Lesbianism. Congresses.', 'Homosexuality. Lesbianism. Societies.', 'Homosexuality. Lesbianism. Dictionaries.', 'Homosexuality. Lesbianism. Computer networks. Electronic information resources (including the Internet and digital libraries).', 'Gay and lesbian studies.', 'Homosexuality. Lesbianism. Biography (Collective).', 'Homosexuality. Lesbianism. Travel.', 'Homosexuality. Lesbianism. Gay parents.', 'Lesbians. Biography. Collective.', 'Lesbians. Biography. Individual, A-Z.', 'Lesbians. General works.', 'Lesbians. Sex instruction.', 'Lesbian mothers.', 'Middle-aged lesbians. Older lesbians.', 'Lesbians. By region or country, A-Z.', 'Gay men. Biography. Collective.', 'Gay men. Biography. Individual, A-Z.', 'Kameny, Frank.', 'Gay men. General works.', 'Gay men. Sex instruction.', 'Gay fathers.', 'Middle-aged gay men. Older gay men.', 'Gay men. By region or country, A-Z.', 'Homosexuality. Lesbianism. General works.', 'Homosexuality. Lesbianism. Juvenile works.', 'Special classes of gay people, A-Z.', 'Special classes of gay people. African Americans.', 'Special classes of gay people. Older gays.', 'Special classes of gay people. Youth.', 'Homosexuality. Lesbianism. By region or country, A-Z.', 'Same-sex relationships. General works.', 'Same-sex relationships. By region or country, A-Z', 'Homophobia. Heterosexism. General works.', 'Homophobia. Heterosexism. By region or country, A-Z.', 'Gay rights movement. Gay liberation movement. Homophile movement. General works.', 'Gay rights movement. Gay liberation movement. Homophile movement. By region or country, A-Z.', 'Gay conservatives.', 'Gay press publications. General works.', 'Gay press publications. By region or country, A-Z', 'Gay and lesbian culture. General works.', 'Gay and lesbian culture. Special topics, A-Z.', 'Gay and lesbian culture. Bathhouses. Saunas. Steam baths.', 'Gay and lesbian culture. Bears.', 'Gay and lesbian culture. Gay pride parades.', 'Gay and lesbian culture. Handkerchief codes.', 'Gay and lesbian culture. Online chat groups.', 'Transvestism. Biography. Collective.', 'Transvestism. Biography. Individual, A-Z.', 'Transvestism. General works.', 'Transvestism. By region or country, A-Z', 'Transsexualism. Biography. Collective.', 'Transsexualism. Biography. Individual, A-Z.', 'Jorgensen, Christine.', 'Transsexualism. General works.', 'Transsexualism. By region or country, A-Z.', 'Parents of gay men or lesbians.', 'Children of gay parents.', 'Same-sex divorce. Gay divorce.', 'Same-sex marriage. General works.', 'Same-sex marriage. By region or country, A-Z.', 'The family. Marriage. Women. Bisexuality in marriage.'], ['Developmental psychology. Child psychology. Special topics. Homophobia.']]\n"
     ]
    }
   ],
   "source": [
    "def find_diversity_topics(div_dict):\n",
    "    #vals = []\n",
    "    topics = []\n",
    "    for k,v in mrcp.items():\n",
    "        try:\n",
    "            entries = div_dict[k]\n",
    "            #vals.append({k: [entry for entry in entries if v in entry['parents']]}) #gives a lot of topics underneath the parent node\n",
    "            topics.append([entry['subject'] for entry in entries if v in entry['parents']])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return topics\n",
    "\n",
    "topics = find_diversity_topics(diversity_subset)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the distribution of key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Debbie\n",
      "[nltk_data]     Olorunisola\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords') #to remove uninformative words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lcc_stop = open(\"lcc_stop_words.txt\", \"r\").read().split(\"\\n\") #stop words for the library of congress classification system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prop_occurrences(topics_lst, lcc_stop, kind = 'by phrase', top_n = 15): #splits by phrase/full subject\n",
    "    all_tags = []\n",
    "\n",
    "    if type(topics_lst[0]) == str:\n",
    "        topics_lst = [topics_lst] #kinda nasty srry, but its how it functions\n",
    "\n",
    "    if kind == 'by phrase':\n",
    "        for i in topics_lst:\n",
    "            tags = '. '.join(i).split('. ')\n",
    "            tags = [x.lower().split('.')[0] for x in tags]\n",
    "            tags = [x for x in tags if not any(sub in x for sub in lcc_stop)] #get rid of common but uninformative loc terms\n",
    "            tags = [' '.join([word for word in x.split(' ') if word not in stop_words]) for x in tags] #get rid of stop words\n",
    "            tags = [x.lstrip().rstrip() for x in tags] #remove leading and trailing ws\n",
    "\n",
    "            all_tags += tags\n",
    "\n",
    "    else: #if by words\n",
    "        for i in topics_lst:\n",
    "            tags = ' '.join(i).split() #split by words\n",
    "            tags = [x.lower().split('.')[0].split(',')[0].split(')')[0] for x in tags] #pruning for commas, periods, and parenthesis\n",
    "            tags = [x for x in tags if x not in lcc_stop and x not in stop_words]\n",
    "            tags = [x.lstrip().rstrip() for x in tags] \n",
    "\n",
    "            all_tags += tags\n",
    "\n",
    "    #make proportions\n",
    "    prop = Counter(all_tags) \n",
    "    prop = dict(prop.most_common(top_n))\n",
    "    total = sum(prop.values())\n",
    "    prop = {k: v/total for k, v in prop.items()}\n",
    "    return prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'homosexuality': 0.15714285714285714, 'lesbianism': 0.15714285714285714, 'biography': 0.11428571428571428, 'gay lesbian culture': 0.1, 'lesbians': 0.07142857142857142, 'gay men': 0.07142857142857142, 'transvestism': 0.05714285714285714, 'transsexualism': 0.05714285714285714, 'homophobia': 0.04285714285714286, 'bisexuality': 0.02857142857142857, 'sex instruction': 0.02857142857142857, 'same-sex relationships': 0.02857142857142857, 'heterosexism': 0.02857142857142857, 'gay rights movement': 0.02857142857142857, 'gay liberation movement': 0.02857142857142857}\n",
      "{'gay': 0.25806451612903225, 'homosexuality': 0.08870967741935484, 'lesbianism': 0.08870967741935484, 'lesbian': 0.07258064516129033, 'biography': 0.07258064516129033, 'lesbians': 0.06451612903225806, 'men': 0.06451612903225806, 'culture': 0.056451612903225805, 'movement': 0.04838709677419355, 'same-sex': 0.04032258064516129, 'transvestism': 0.03225806451612903, 'transsexualism': 0.03225806451612903, 'marriage': 0.03225806451612903, 'sex': 0.024193548387096774, 'bisexuality': 0.024193548387096774}\n"
     ]
    }
   ],
   "source": [
    "prop_div = get_prop_occurrences(topics, lcc_stop)\n",
    "print(prop_div)\n",
    "print(get_prop_occurrences(topics, lcc_stop, kind = 'by words'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the same distribution of topics for books on the syllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex role', 'The Family', 'Marriage', 'Women', 'Sex role', 'The Family', 'Marriage', 'Women', 'Early childhood education', 'Theory and practice of education', 'Theory and practice of education', 'Elementary or public school education', 'Preschool education', 'Nursery schools', 'Theory and practice of education', 'Early childhood education', 'Theory and practice of education', 'Community and the school', 'Home and school', 'Special aspects of education', 'Social aspects of education', 'School management and discipline', 'Theory and practice of education', 'School administration and organization', 'Consciousness', 'Cognition', 'Psychology', 'Fiction and juvenile belles lettres', 'Juvenile belles lettres', 'Multicultural education (General)', 'Special aspects of education', 'Types of education', 'The Family', 'Marriage', 'Women', 'Children', 'Child development', 'The family', 'Marriage', 'Home']\n",
      "{'family': 0.16, 'marriage': 0.16, 'women': 0.12, 'sex role': 0.08, 'early childhood education': 0.08, 'elementary public school education': 0.04, 'preschool education': 0.04, 'nursery schools': 0.04, 'community school': 0.04, 'home school': 0.04, 'school management discipline': 0.04, 'school administration organization': 0.04, 'consciousness': 0.04, 'cognition': 0.04, 'psychology': 0.04}\n"
     ]
    }
   ],
   "source": [
    "topics_syll = []\n",
    "for i in lccn_tup:\n",
    "   topics_syll = [x.lstrip() for x in tags3]\n",
    "\n",
    "print(topics_syll)\n",
    "\n",
    "prop_syll = get_prop_occurrences(topics_syll, lcc_stop)\n",
    "print(prop_syll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up books in the range with a set list of important topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_subjects(lcc, topics, field = 'subject', limit = 1, exact_string_matching = False):\n",
    "    if type(topics) == str:\n",
    "        time.sleep(2) #being polite\n",
    "        response = requests.get(f'https://openlibrary.org/search.json?q=lcc:{lcc}&subject={topics}&fields={field}&limit={limit}').json()\n",
    "\n",
    "        if bool(response['docs']): #falsy\n",
    "            return response['docs']\n",
    "        else:\n",
    "            return '' #nothing returned\n",
    "\n",
    "    elif type(topics) == list:    \n",
    "        q = f'https://openlibrary.org/search.json?q=lcc:{lcc}&fields={field}&limit={limit}'\n",
    "\n",
    "        if exact_string_matching: #for cases where a single word is used\n",
    "            \n",
    "            topics = list(map(lambda x: urllib.parse.quote(x.encode(\"utf-8\")), topics)) #encode tags\n",
    "            topics = list(map(lambda x: f\"\\\"{x}\\\"\", topics)) #exact string matching\n",
    "\n",
    "            #topics = '+OR+'.join(topics) #comma (,) and pipe (|) are similar AND, not OR for some reason\n",
    "            topics = ''.join(list(map(lambda x: f'&subject={x}', topics)))\n",
    "            q += topics\n",
    "        \n",
    "        else:\n",
    "            topics = ','.join(topics)\n",
    "            q += topics\n",
    "        \n",
    "        print(q)\n",
    "\n",
    "        time.sleep(2) #being polite\n",
    "        response = requests.get(q).json()\n",
    "        \n",
    "        if bool(response['docs']): #falsy\n",
    "            return response['docs']\n",
    "        else:\n",
    "            return '' #nothing returned\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use most recent common parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_syll = get_prop_occurrences(topics_syll, lcc_stop, 'by word', 3) #by phrase isn't working at the moment\n",
    "prop_div = get_prop_occurrences(topics, lcc_stop, 'by word', 3)\n",
    "\n",
    "subject_terms = list(prop_div.keys()) + list(prop_syll.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openlibrary.org/search.json?q=lcc:[HQ1 TO HQ2044]&fields=title&limit=3&subject=\"gay\"&subject=\"homosexuality\"&subject=\"lesbianism\"&subject=\"education\"&subject=\"school\"&subject=\"family\"\n",
      "[{'title': 'Men are From Mars, Women are From Venus'}, {'title': 'Being Mortal'}, {'title': 'Women Who Love Too Much'}]\n",
      "https://openlibrary.org/search.json?q=lcc:[LB5 TO LB3640]&fields=title&limit=3&subject=\"gay\"&subject=\"homosexuality\"&subject=\"lesbianism\"&subject=\"education\"&subject=\"school\"&subject=\"family\"\n",
      "[{'title': 'Stick Man'}, {'title': \"Représentation du monde chez l'enfant\"}, {'title': \"A Mother's Reckoning\"}]\n",
      "https://openlibrary.org/search.json?q=lcc:[LC8 TO LC6691]&fields=title&limit=3&subject=\"gay\"&subject=\"homosexuality\"&subject=\"lesbianism\"&subject=\"education\"&subject=\"school\"&subject=\"family\"\n",
      "[{'title': 'Ko munsŏ chipsŏng'}, {'title': 'Let her fly'}, {'title': 'Household education. By Harriet Martineau'}]\n",
      "https://openlibrary.org/search.json?q=lcc:[BF1 TO BF990]&fields=title&limit=3&subject=\"gay\"&subject=\"homosexuality\"&subject=\"lesbianism\"&subject=\"education\"&subject=\"school\"&subject=\"family\"\n",
      "[{'title': 'The 7 Habits of Highly Effective People'}, {'title': 'The Shipping News'}, {'title': 'Psychologische Typen'}]\n",
      "https://openlibrary.org/search.json?q=lcc:[PZ1 TO PZ90]&fields=title&limit=3&subject=\"gay\"&subject=\"homosexuality\"&subject=\"lesbianism\"&subject=\"education\"&subject=\"school\"&subject=\"family\"\n",
      "[{'title': 'Little men'}, {'title': 'Crooked House'}, {'title': 'The Railway Children'}]\n"
     ]
    }
   ],
   "source": [
    "suggestions = []\n",
    "for k,v in mrcp.items(): \n",
    "    if '-' in v:\n",
    "        lst = v.split('-')\n",
    "        lccn_query = '[' + lst[0] + ' TO ' + k + lst[1] + ']'\n",
    "        print(search_subjects(lccn_query, subject_terms, 'title', 3, True)) #AT LEAST ONE search is not working i fear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Rao's Entropy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_hub\n",
    "from sentence_transformers import SentenceTransformer #\"tensorflow>=1.7.0\", tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for embeddings\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = tensorflow_hub.load(module_url)\n",
    "\n",
    "print (\"module %s loaded\" % module_url)\n",
    "\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a measure of entropy over the syllabus, this is a comparison between the syllabus and the diversity area topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rao's Entropy (Diversity): 2.07819346733668\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model for sentence embeddings\n",
    "\n",
    "# Define Rao's entropy formula\n",
    "def raos_entropy(all_cats):\n",
    "    #i'm aware this is presently incorrect bc the probably of topics is not btwn 0 and 1, but This Is a Start!\n",
    "    entropy = 0.0\n",
    "\n",
    "    # Calculate pairwise cosine distances between topics\n",
    "    tags = list(all_cats.keys())\n",
    "    embeddings = embed(tags) #needs to be embedded over one space\n",
    "    distance_matrix = np.inner(embeddings, embeddings) #cosine sim\n",
    "\n",
    "    # rao's entropy\n",
    "    rqe = 0.0\n",
    "\n",
    "    for i, cat_i in enumerate(tags):\n",
    "        for j, cat_j in enumerate(tags):\n",
    "            p_i = all_cats.get(cat_i, 0) # Probability for category i (fall through if 0)\n",
    "            p_j = all_cats.get(cat_j, 0)\n",
    "            #print(p_i, p_j)\n",
    "            # cosine distance (1 - cosine similarity)\n",
    "            distance = 1 - distance_matrix[i, j]\n",
    "            #print(distance)\n",
    "            \n",
    "            rqe += p_i * p_j * distance\n",
    "\n",
    "    return rqe\n",
    "\n",
    "# Calculate diversity using Rao's entropy\n",
    "all_cats = {**prop_syll, **prop_div}\n",
    "entropy = raos_entropy(all_cats)\n",
    "print(f\"Rao's Entropy (Diversity): {entropy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be implemented: RQE for set of book recommendations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "founders-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
